{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping to generate RSS feed for new positions in economics\n",
    "This application is using three main sources to retrieve information about the new job posts:\n",
    "1. [NBER](https://www.nber.org/career-resources/research-assistant-positions-not-nber)\n",
    "2. [Predoc](https://predoc.org/opportunities)\n",
    "3. [EconJobMarket](https://econjobmarket.org/market)\n",
    "   \n",
    "The packeges that are needed are **requests**, **beautifulsoup4**,**MIMEtext**. As a first step we recall them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET  # For XML handling\n",
    "import requests  # For HTTP requests\n",
    "import certifi  # For SSL certification verification\n",
    "from bs4 import BeautifulSoup  # For web scraping\n",
    "import re  # For regular expressions\n",
    "import os  # For file and environment variable management\n",
    "import pandas as pd  # For data manipulation\n",
    "import smtplib  # For sending emails\n",
    "from email.mime.text import MIMEText  # For constructing email messages\n",
    "from email.mime.multipart import MIMEMultipart  # For handling email attachments\n",
    "from IPython.display import Markdown, display  # For displaying tables in Jupyter\n",
    "from dotenv import load_dotenv  # For loading environment variables\n",
    "import urllib3  # For managing HTTP connections\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import datetime\n",
    "# Suppress SSL warnings for sites with invalid certificates (if necessary)\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()  # For email credentials (SENDER_EMAIL, SENDER_PASSWORD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PREDOC_URL = \"https://predoc.org/opportunities\"\n",
    "NBER_URL = \"https://www.nber.org/career-resources/research-assistant-positions-not-nber\"\n",
    "EJM_URL = \"https://econjobmarket.org/market\"\n",
    "XML_FILE = \"jobs.xml\"\n",
    "\n",
    "# Define your GitHub repository link\n",
    "GITHUB_REPO_URL = \"https://github.com/RickyJ99/RA-rss\"\n",
    "GITHUB_ISSUE_URL = f\"{GITHUB_REPO_URL}/issues\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the html\n",
    "The following functions are downloading the HTML content from the sources and it save it in the foulder sources.\n",
    "For PREDOC there is a issue with certificate so it is easy to use curl (bash MacOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14987.38s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "14993.11s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  407k  100  407k    0     0   2054      0  0:00:08  0:00:01  0:00:07 52039150k      0  0:00:02  0:00:02 --:--:--  151k\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p sources\n",
    "!curl -L \"https://predoc.org/opportunities\" -o \"sources/predoc.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading https://predoc.org/opportunities: HTTPSConnectionPool(host='predoc.org', port=443): Max retries exceeded with url: /opportunities (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\n",
      "Downloaded HTML from https://www.nber.org/career-resources/research-assistant-positions-not-nber to sources/nber.html\n",
      "Downloaded HTML from https://econjobmarket.org/market to sources/ejm.html\n"
     ]
    }
   ],
   "source": [
    "def download_html(url, filename):\n",
    "    \"\"\"\n",
    "    Downloads the HTML content from the given URL and saves it to the specified filename.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, verify=certifi.where())\n",
    "        response.raise_for_status()\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "        print(f\"Downloaded HTML from {url} to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "# Ensure the 'sources' folder exists.\n",
    "os.makedirs(\"sources\", exist_ok=True)\n",
    "\n",
    "# Download HTML content for each source.\n",
    "download_html(PREDOC_URL, \"sources/predoc.html\")\n",
    "download_html(NBER_URL, \"sources/nber.html\")\n",
    "download_html(EJM_URL, \"sources/ejm.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Main Field Helper Function üîë\n",
    "\n",
    "The `extract_main_field` function analyzes a given text to determine which research fields are mentioned. It searches for multiple keywords in a **case-insensitive** manner. If one or more keywords are found, it returns them as a comma‚Äëseparated string. If \"N/A\" are found, it returns `\"N/A\"`.\n",
    "\n",
    "### Keywords Included:\n",
    "- **Economics**\n",
    "- **Macroeconomics**\n",
    "- **Microeconomics**\n",
    "- **Labour**\n",
    "- **Industrial Organization**\n",
    "- **Enterpreneurship**\n",
    "- **Healthcare**\n",
    "- **Discrimination**\n",
    "- **Finance**\n",
    "- **Public Policy**\n",
    "\n",
    "You can extend this list with additional fields in economics as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_field(text):\n",
    "    \"\"\"\n",
    "    Looks for keywords in the provided text.\n",
    "    Keywords: Economics, Macroeconomics, Microeconomics, Labour, Industrial Organization,\n",
    "    Enterpreneurship, Healthcare, Discrimination, Finance, Public Policy.\n",
    "    Returns a comma-separated string of all found keywords or \"None\" if none are found.\n",
    "    \"\"\"\n",
    "    keywords = [\n",
    "        \"Economics\", \"Macroeconomics\", \"Microeconomics\",\"Microeconomic theory\", \"Macroeconomic theory\"\n",
    "        \"Labour\", \"Industrial Organization\", \"Entrepreneurship\",\n",
    "        \"Healthcare\", \"Discrimination\", \"Finance\", \"Public Policy\", \"Local Economic Policy\", \"Climate\"\n",
    "    ]\n",
    "    \n",
    "    found = []\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in text.lower():\n",
    "            found.append(keyword)\n",
    "    \n",
    "    if found:\n",
    "        # Remove duplicates while preserving order and return as a comma-separated string.\n",
    "        unique_keywords = list(dict.fromkeys(found))\n",
    "        return \", \".join(unique_keywords)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function: `extract_program_type(text)`**\n",
    "\n",
    "- **Purpose:**  \n",
    "  This function takes a string as input (which might be a job title or description) and determines the program type based on certain keywords.\n",
    "\n",
    "- **How It Works:**  \n",
    "  1. **Convert to Lowercase:**  \n",
    "     The input text is converted to lowercase to ensure case-insensitive matching.\n",
    "  2. **Keyword Checks:**  \n",
    "     - If the text contains any variation of \"predoctoral\" (e.g., \"predoctoral\", \"pre doc\", \"pre-doc\", \"predoc\"), it returns **\"PreDoctoral Program\"**.\n",
    "     - If the text contains any variation of \"postdoc\" (e.g., \"postdoc\", \"post doc\", \"post-doc\", \"postdoctoral\", \"post doctoral\"), it returns **\"Post Doc\"**.\n",
    "     - If the text contains \"phd\" or \"ph.d\", it returns **\"PhD\"**.\n",
    "     - If the text mentions \"research assistant\" or even \"ra\" (for example, in abbreviated or extensive form), it returns **\"Research Assistant\"**.\n",
    "  3. **Default Category:**  \n",
    "     If \"N/A\" of the keywords are found, the function defaults to returning **\"Research Assistant\"**.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_program_type(text):\n",
    "    \"\"\"\n",
    "    Analyzes the provided text (e.g., a job title or description) to determine the program type.\n",
    "    \n",
    "    Keywords used:\n",
    "      - \"PreDoctoral Program\" if the text includes variations like \"predoctoral\", \"predoc\", etc.\n",
    "      - \"Post Doc\" if the text includes variations like \"postdoc\", \"post-doctoral\", etc.\n",
    "      - \"PhD\" if the text includes \"phd\" or \"ph.d\".\n",
    "      - \"Research Assistant\" (RA) for all other cases.\n",
    "    \n",
    "    Returns:\n",
    "      A string representing the program type.\n",
    "    \"\"\"\n",
    "    # Convert the text to lowercase for case-insensitive matching. üîç\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Check for PreDoctoral indicators. üéì\n",
    "    if any(kw in text_lower for kw in [\"predoctoral\", \"pre doc\", \"pre-doc\", \"predoc\"]):\n",
    "        return \"PreDoctoral Program\"\n",
    "    \n",
    "    # Check for Post Doc indicators. üìö\n",
    "    elif any(kw in text_lower for kw in [\"postdoc\", \"post doc\", \"post-doc\", \"postdoctoral\", \"post doctoral\"]):\n",
    "        return \"Post Doc\"\n",
    "    \n",
    "    # Check for PhD indicators. üéì\n",
    "    elif \"phd\" in text_lower or \"ph.d\" in text_lower:\n",
    "        return \"PhD\"\n",
    "    \n",
    "    # Check for Research Assistant indicators. üíº\n",
    "    elif \"research assistant\" in text_lower or \"ra\" in text_lower:\n",
    "        return \"Research Assistant\"\n",
    "    \n",
    "    # Default category is Research Assistant (RA). üîÑ\n",
    "    else:\n",
    "        return \"Research Assistant\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Web Scraping Section üöÄ\n",
    "\n",
    "In this section, we set up our web scraping functionality. Our goal is to **extract job details** from pre-doctoral opportunities pages (in this example, from [predoc.org](https://predoc.org/opportunities)). We assume that the HTML content has already been downloaded and saved locally in the `sources` folder.\n",
    "\n",
    "### Predoc\n",
    "What This Section Does:\n",
    "- **Reads the Local HTML File üìÇ:**  \n",
    "  We read the downloaded HTML file (`sources/predoc.html`). If the file isn't found, the code prompts you to download it first.\n",
    "  \n",
    "- **Parses the HTML Content ü•£:**  \n",
    "  Using BeautifulSoup, the code parses the HTML to locate the container that holds the opportunity details.\n",
    "  \n",
    "- **Extracts Key Information üîç:**  \n",
    "  For each job posting, the function extracts:\n",
    "  - **Program Title** and **Link** from the `<h2>` element.\n",
    "  - Additional details (like **sponsor**, **institution**, **fields of research**, and **deadline**) from the \"copy\" `<div>`.\n",
    "  \n",
    "- **Determines the Main Field üîë:**  \n",
    "  It combines several text fields and passes them to an auxiliary function (`extract_main_field()`) that determines the primary focus (e.g., Economics, Microeconomics, Finance, etc.).\n",
    "\n",
    "- **Returns the Data as a List üì§:**  \n",
    "  Each job is stored as a dictionary, and the function returns a list of these dictionaries.\n",
    "\n",
    "> **Note:**  \n",
    "> Make sure to download the HTML file before running the scraper (therefore run the previous chunks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| source   | program_title                                | link                   | sponsor                                                    | institution                                                                             | fields                                                                            | deadline                                                                                                                                                                                                            | university   | program_type   | publication_date   | main_field                  |\n",
       "|:---------|:---------------------------------------------|:-----------------------|:-----------------------------------------------------------|:----------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------|:---------------|:-------------------|:----------------------------|\n",
       "| Predoc   | Research Associates                          | https://bit.ly/3Xhfcvq | N/A                                                        | N/A                                                                                     | Education, Finance, Labor, Macro, Public Policy, and Urban                        | Rolling In addition to a multi-institutional job pool, this website also provides general information about opportunities within the Federal Reserve System as well as up-to-date information re specific openings. | N/A          | N/A            | N/A                | Finance, Public Policy      |\n",
       "| Predoc   | Pre-Doctoral Positions                       | https://bit.ly/3CM4IxV | Abhishek Nagaraj (UC Berkeley) and Matteo Tranchero (Penn) | UC Berkeley‚Äôs Haas School of Business; Wharton School of the University of Pennsylvania | Applied economics, innovation, entrepreneurship, data science and tech innovation | Rolling                                                                                                                                                                                                             | N/A          | N/A            | N/A                | Economics, Entrepreneurship |\n",
       "| Predoc   | Pre-Doctoral Technical Associate             | https://bit.ly/4hBFgtU | N/A                                                        | N/A                                                                                     | N/A                                                                               | N/A                                                                                                                                                                                                                 | N/A          | N/A            | N/A                |                             |\n",
       "| Predoc   | Pre-Doctoral Technical Associate             | https://bit.ly/4er9iOY | N/A                                                        | N/A                                                                                     | N/A                                                                               | N/A                                                                                                                                                                                                                 | N/A          | N/A            | N/A                |                             |\n",
       "| Predoc   | Pre-Doctoral Research Associate in Economics | https://bit.ly/4jQlfBs | Matthew Pecenco                                            | Brown University                                                                        | Labor, Crime, Housing                                                             | Applications will be accepted and reviewed on a rolling basis.                                                                                                                                                      | N/A          | N/A            | N/A                | Economics                   |\n",
       "| Predoc   | Full-Time Research Assistant                 | https://bit.ly/4hwY3a0 | Matthew Baron                                              | National Bureau of Economic Research                                                    | Banking, Financial Crises, Financial History                                      | Rolling                                                                                                                                                                                                             | N/A          | N/A            | N/A                |                             |\n",
       "| Predoc   | Pre-Doctoral Fellowship                      | https://bit.ly/3WXU7GY | Hans-Joachim Voth                                          | University of Zurich                                                                    | Economic History, Political Economy, Cultural Economics                           | Applications will be reviewed immediately and are welcome until all positions are filled.                                                                                                                           | N/A          | N/A            | N/A                | Economics                   |\n",
       "| Predoc   | Research Professional in Accounting          | https://bit.ly/4hyJouK | Professor Philip Berger                                    | The University of Chicago Booth School of Business                                      | Accounting, corporate finance, and labor economics.                               | Applications are reviewed on a rolling basis; the initial full review will be March 15, 2025.                                                                                                                       | N/A          | N/A            | N/A                | Economics, Finance          |\n",
       "| Predoc   | Research Professional in Marketing           | https://bit.ly/3Eupeng | Professor Andreas Kraft                                    | University of Chicago Booth School of Business                                          | N/A                                                                               | N/A                                                                                                                                                                                                                 | N/A          | N/A            | N/A                |                             |\n",
       "| Predoc   | Research Professional in Behavioral Science  | https://bit.ly/3QkttnL | Professor Alexander Todorov                                | University of Chicago Booth School of Business                                          | Behavioral Science                                                                | Applications are reviewed on a rolling basis; the initial full review will be March 1, 2025.                                                                                                                        | N/A          | N/A            | N/A                |                             |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scrape_predoc():\n",
    "    \"\"\"\n",
    "    Scrapes the pre-doctoral opportunities page from the local HTML file\n",
    "    and extracts job details.\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "    \n",
    "    # Attempt to read the local HTML file. üìÇ\n",
    "    try:\n",
    "        with open(\"sources/predoc.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "            html = f.read()\n",
    "    except Exception as e:\n",
    "        print(\"Error reading sources/predoc.html. Please download the HTML from predoc before proceeding. üö´\")\n",
    "        return jobs  # Return an empty list if the file can't be read.\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup. ü•£\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Find the container holding the opportunities using a regex on the class name. üîç\n",
    "    container = soup.find(\"div\", class_=re.compile(\"Opportunities\"))\n",
    "    if not container:\n",
    "        print(\"No Predoc container found. üò¢\")\n",
    "        return jobs\n",
    "    \n",
    "    # Loop over each article element within the container. üìù\n",
    "    articles = container.find_all(\"article\")\n",
    "    for article in articles:\n",
    "        job = {}\n",
    "        job[\"source\"] = \"Predoc\"  # Mark the source as 'predoc'. üåü\n",
    "        \n",
    "        # Extract the title and link from the <h2> element. üè∑Ô∏è\n",
    "        h2 = article.find(\"h2\")\n",
    "        if h2:\n",
    "            a_tag = h2.find(\"a\")\n",
    "            if a_tag:\n",
    "                job[\"program_title\"] = a_tag.get_text(strip=True)\n",
    "                job[\"link\"] = a_tag.get(\"href\", \"N/A\").strip()\n",
    "            else:\n",
    "                job[\"program_title\"] = \"N/A\"\n",
    "                job[\"link\"] = \"N/A\"\n",
    "        else:\n",
    "            job[\"program_title\"] = \"N/A\"\n",
    "            job[\"link\"] = \"N/A\"\n",
    "        \n",
    "        # Extract details from the \"copy\" div. üóíÔ∏è\n",
    "        copy_div = article.find(\"div\", class_=\"copy\")\n",
    "        if copy_div:\n",
    "            p = copy_div.find(\"p\")\n",
    "            if p:\n",
    "                text = p.get_text(separator=\" \", strip=True)\n",
    "                # Use regex to capture specific fields from the text. üîç\n",
    "                researcher_match = re.search(r\"Sponsoring Researcher\\(s\\):\\s*(.*?)\\s*Sponsoring Institution:\", text)\n",
    "                institution_match = re.search(r\"Sponsoring Institution:\\s*(.*?)\\s*Fields of Research\", text)\n",
    "                fields_match = re.search(r\"Fields of Research\\s*:\\s*(.*?)\\s*Deadline:\", text)\n",
    "                deadline_match = re.search(r\"Deadline:\\s*(.*)\", text)\n",
    "                job[\"sponsor\"] = researcher_match.group(1).strip() if researcher_match else \"N/A\"\n",
    "                job[\"institution\"] = institution_match.group(1).strip() if institution_match else \"N/A\"\n",
    "                job[\"fields\"] = fields_match.group(1).strip() if fields_match else \"N/A\"\n",
    "                job[\"deadline\"] = deadline_match.group(1).strip() if deadline_match else \"N/A\"\n",
    "            else:\n",
    "                job[\"sponsor\"] = \"N/A\"\n",
    "                job[\"institution\"] = \"N/A\"\n",
    "                job[\"fields\"] = \"N/A\"\n",
    "                job[\"deadline\"] = \"N/A\"\n",
    "        else:\n",
    "            job[\"sponsor\"] = \"N/A\"\n",
    "            job[\"institution\"] = \"N/A\"\n",
    "            job[\"fields\"] = \"N/A\"\n",
    "            job[\"deadline\"] = \"N/A\"\n",
    "        \n",
    "        # Add additional fields for consistency. üõ†Ô∏è\n",
    "        job[\"university\"] = \"N/A\"\n",
    "        job[\"program_type\"] = \"N/A\"\n",
    "        job[\"publication_date\"] = \"N/A\"\n",
    "        \n",
    "        # Determine the main field by combining text from various fields. üîë\n",
    "        text_to_search = \" \".join([job.get(\"fields\", \"N/A\"), job.get(\"program_title\", \"N/A\"), job.get(\"institution\", \"N/A\")])\n",
    "        job[\"main_field\"] = extract_main_field(text_to_search)\n",
    "        \n",
    "        # Append the extracted job details to the jobs list. ‚úÖ\n",
    "        jobs.append(job)\n",
    "    \n",
    "    # Return the list of all extracted job details. üì§\n",
    "    return jobs\n",
    "df  = pd.DataFrame(scrape_predoc()).head(10).to_markdown(index=False)\n",
    "display(Markdown(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Section for NBER (Local HTML) üîé\n",
    "\n",
    "In this section, we extract job details from the locally saved NBER page HTML file. The function follows these steps:\n",
    "\n",
    "- **üìÇ Read the Local HTML File:**  \n",
    "  The function attempts to read `sources/nber.html`. If the file isn't found, it prints an error message and returns an empty list.\n",
    "\n",
    "- **ü•£ Parse HTML with BeautifulSoup:**  \n",
    "  The HTML content is parsed so we can navigate and extract the data.\n",
    "\n",
    "- **üîç Locate the Container:**  \n",
    "  It finds the `<div>` with class `page-header__intro-inner` that holds the job details.\n",
    "\n",
    "- **‚úÇÔ∏è Skip Header Paragraphs:**  \n",
    "  The first three `<p>` elements are skipped as they contain header information.\n",
    "\n",
    "- **üìã Extract Job Details:**  \n",
    "  For each job posting, the function extracts:\n",
    "  - Program title  \n",
    "  - Sponsor  \n",
    "  - Institution  \n",
    "  - Fields of research  \n",
    "  - Job link  \n",
    "  If any of these details are missing, it defaults to `\"N/A\"`.\n",
    "\n",
    "- **üîë Determine Main Field:**  \n",
    "  It combines relevant text and uses the helper function `extract_main_field()` (which should be defined elsewhere) to determine the primary research area.\n",
    "\n",
    "- **‚úÖ Return the Jobs List:**  \n",
    "  Finally, all extracted job entries are stored in a list and returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| source   | program_title                                                 | sponsor                       | institution                                                                        | fields                                                                     | program_type        | main_field                | link                                                                                                                                      | deadline   | publication_date   |\n",
       "|:---------|:--------------------------------------------------------------|:------------------------------|:-----------------------------------------------------------------------------------|:---------------------------------------------------------------------------|:--------------------|:--------------------------|:------------------------------------------------------------------------------------------------------------------------------------------|:-----------|:-------------------|\n",
       "| NBER     | Predoctoral Research Analyst                                  | Josh Rauh                     | Hoover Institution                                                                 | State, Local Economic Policy                                               | PreDoctoral Program | Local Economic Policy     | https://careersearch.stanford.edu/jobs/research-analyst-for-state-and-local-government-initiative-27190                                   | N/A        | N/A                |\n",
       "| NBER     | Postdoctoral Research Fellowship                              | Josh Rauh                     | Hoover Institution                                                                 | State, Local Economic Policy                                               | Post Doc            | Local Economic Policy     | https://applyrtf.hoover.org/                                                                                                              | N/A        | N/A                |\n",
       "| NBER     | Predoctoral Research Associate                                | Paul A. Gompers               | Harvard Business School                                                            | Entrepreneurship, Finance                                                  | PreDoctoral Program | Entrepreneurship, Finance | https://www.dropbox.com/scl/fi/71ook3ulz90ncx67qvf8d/Gompers_predoc_job_posting_2025.pdf?rlkey=nqoh9hutr0gprkm8xyukhrm00&st=9h2t9x7v&dl=0 | N/A        | N/A                |\n",
       "| NBER     | Predoctoral Fellow                                            | Amanda Pallais                | Harvard University                                                                 | Labor Economics                                                            | PreDoctoral Program | Economics                 | https://academicpositions.harvard.edu/postings/14690                                                                                      | N/A        | N/A                |\n",
       "| NBER     | Full-Time Pre-Doctoral Fellow/Research Assistant              | Stephan Heblich               | University of Toronto, Department of Economics and Rotman School of Management     | Applied Economics                                                          | PreDoctoral Program | Economics                 | https://foslab.org/join-our-team/pre-doc-fellowships/pre-doctoral-fellowship-in-applied-economics/                                        | N/A        | N/A                |\n",
       "| NBER     | Pre-doctoral Research Fellows                                 | Gordon Hanson and Dani Rodrik | Harvard Kennedy School                                                             | Regional dimensions of inequality in the United States and other countries | PreDoctoral Program |                           | https://www.hks.harvard.edu/centers/wiener/programs/economy/about/opportunities/pre-doc-fellow-2025                                       | N/A        | N/A                |\n",
       "| NBER     | Research Professional                                         | Michael Greenstone            | University of Chicago, Climate Impact Lab                                          | Environment, Climate                                                       | Research Assistant  | Climate                   | https://job-boards.greenhouse.io/uchicagoepic/jobs/6349570003                                                                             | N/A        | N/A                |\n",
       "| NBER     | Pre-doctoral Fellow                                           | Lisa B. Kahn                  | University¬†of Rochester                                                            | Labor Economics                                                            | PreDoctoral Program | Economics                 | https://docs.google.com/forms/d/e/1FAIpQLSd2VitZ6wmUBL0Qyqiyg-zj-hSOjXIuMVke4XSJI4bLri0VDg/viewform?pli=1                                 | N/A        | N/A                |\n",
       "| NBER     | Monitoring &amp; Evaluation Specialist, EPIC Air Quality Fund | Michael Greenstone            | University of Chicago (but not a direct hire, will work with an EOR)               | Air Quality, Environment, Climate                                          | Research Assistant  | Climate                   | https://epic.uchicago.edu/opportunities/monitoring-evaluation-specialist-epic-air-quality-fund/                                           | N/A        | N/A                |\n",
       "| NBER     | Research Analyst                                              | Dean Karlan, Christopher Udry | Global Poverty Research Lab, Kellogg School of Management, Northwestern University | Development economics                                                      | Research Assistant  | Economics                 | https://www.povertyactionlab.org/careers/research-analyst-global-poverty-research-lab-kellogg-school-management-northwestern              | N/A        | N/A                |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scrape_nber():\n",
    "    \"\"\"\n",
    "    Scrapes the NBER research assistant positions page from a local HTML file\n",
    "    and extracts job details.\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "    \n",
    "    # Attempt to read the local HTML file. üìÇ\n",
    "    try:\n",
    "        with open(\"sources/nber.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "            html = f.read()\n",
    "    except Exception as e:\n",
    "        print(\"Error reading sources/nber.html. Please download the HTML from NBER before proceeding. üö´\")\n",
    "        return jobs  # Return an empty list if the file can't be read.\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup. ü•£\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Find the container holding the job details using its class name. üîç\n",
    "    container = soup.find(\"div\", class_=\"page-header__intro-inner\")\n",
    "    if container:\n",
    "        # Get all <p> elements inside the container. üìù\n",
    "        paragraphs = container.find_all(\"p\")\n",
    "        # Skip the first three header paragraphs. ‚úÇÔ∏è\n",
    "        for p in paragraphs[2:]:\n",
    "            job = {}\n",
    "            job[\"source\"] = \"NBER\"  # Mark the source as NBER. üåü\n",
    "            parts = p.decode_contents().split(\"<br>\")[0].split(\"<br/>\")\n",
    "\n",
    "\n",
    "            if len(parts) >= 4:\n",
    "                job[\"program_title\"]        = parts[0].strip()\n",
    "                job[\"sponsor\"]              = parts[1].replace(\"NBER Sponsoring Researcher(s):\",\"\").strip()\n",
    "                job[\"institution\"]          = parts[2].replace(\"Institution:\",\"\").strip()\n",
    "                if len(parts[3].replace(\"Field(s) of Research:\",\"\").strip().split(\"&amp\"))>1:\n",
    "                    fields = \"\".join(field.strip() for field in parts[3].replace(\"Field(s) of Research:\",\"\").strip().split(\"&amp\"))\n",
    "                else:\n",
    "                    fields         = parts[3].replace(\"Field(s) of Research:\",\"\").strip()\n",
    "                if len(fields.split(\";\")) > 1:\n",
    "                    fields = \", \".join(field.strip() for field in fields.split(\";\"))\n",
    "\n",
    "                if len(fields.split(\":\")) > 1:\n",
    "                    fields = fields.split(\":\")[1]\n",
    "                job[\"fields\"]               =   fields\n",
    "                job[\"program_type\"]         = extract_program_type(job[\"program_title\"])\n",
    "                # Combine text fields (program title and university) to determine the main field. üîë\n",
    "                text_to_search =  fields\n",
    "                job[\"main_field\"] = extract_main_field(text_to_search)\n",
    "                # Extract the job link from the HTML in the last part. üîó\n",
    "                link_soup = BeautifulSoup(parts[4], \"html.parser\")\n",
    "                a_tag = link_soup.find(\"a\")\n",
    "                job[\"link\"]                 = a_tag[\"href\"] if a_tag else \"\"\n",
    "                job[\"deadline\"]             = \"N/A\"  # Deadline not provided. ‚è∞\n",
    "                job[\"publication_date\"]     = \"N/A\"\n",
    "                # Append the extracted job to our list. ‚úÖ\n",
    "                jobs.append(job)\n",
    "    else:\n",
    "        print(\"NBER container not found. üò¢\")\n",
    "    \n",
    "    # Return the list of all extracted job details. üì§\n",
    "    return jobs\n",
    "df  = pd.DataFrame(scrape_nber()).head(10).to_markdown(index=False)\n",
    "display(Markdown(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping Section for EJM (Econ Job Market) üîé\n",
    "\n",
    "This function is designed to scrape job postings from the Econ Job Market (EJM) page. It performs the following tasks:\n",
    "\n",
    "- **üåê Fetching the Page:**  \n",
    "  It sends an HTTP GET request to the EJM URL using the `requests` library.\n",
    "\n",
    "- **ü•£ Parsing HTML:**  \n",
    "  The response content is parsed with BeautifulSoup to create a DOM structure for extraction.\n",
    "\n",
    "- **üîç Locating Job Panels:**  \n",
    "  It finds all `<div>` elements with the classes `\"panel panel-info\"`, each representing a job posting.\n",
    "\n",
    "- **üè∑Ô∏è Extracting Job Details:**  \n",
    "  For each panel, it extracts:\n",
    "  - **Job Title & Link:** Located within an `<a>` tag with an ID starting with \"title-\".  \n",
    "  - **University & Program Type:** Extracted from `<div>` elements with class `\"col-md-4\"` and `\"col-md-2\"`, respectively.\n",
    "  - **Publication Date & Deadline:** Extracted from `<div>` elements with class `\"col-md-2\"`.\n",
    "  - **Default Values:** Fields such as **sponsor**, **institution**, and **fields** are set to `\"N/A\"` since they're not provided.\n",
    "  \n",
    "- **üîë Determining the Main Field:**  \n",
    "  It combines the program title and university information to deduce the primary research field using the helper function `extract_main_field()`.\n",
    "\n",
    "- **‚úÖ Building the Result List:**  \n",
    "  Each job is stored as a dictionary, and all such dictionaries are appended to a list which is then returned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/nzwwg11s06sf2dv5349vbjxh0000gn/T/ipykernel_1106/4290271320.py:156: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  apply_paragraph = collapse_div.find(\"p\", text=re.compile(r\"To\\s+Apply\", re.IGNORECASE))\n",
      "/var/folders/zd/nzwwg11s06sf2dv5349vbjxh0000gn/T/ipykernel_1106/4290271320.py:163: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  apply_a = collapse_div.find(\"a\", href=True, text=re.compile(r\"apply\", re.IGNORECASE))\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| source   | program_title                                                                   | location              | start_date   | duration             | department                                                       | university                            | program_type                 | fields                                                                                                                                                                                                                                                                                          | publication_date   | deadline    | sponsor                                                                                                                          | institution                           | main_field                                                               | degree_required   | salary_range         | link                                                                                                                                                                                                                             |\n",
       "|:---------|:--------------------------------------------------------------------------------|:----------------------|:-------------|:---------------------|:-----------------------------------------------------------------|:--------------------------------------|:-----------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------|:------------|:---------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------|:-------------------------------------------------------------------------|:------------------|:---------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
       "| ejm      | Faculty of Economics at Plaksha University, India                               | Mohali,               | N/A          | Continuing/permanent | Plaksha University                                               | N/A                                   | Various position types       | Development Growth, Econometrics, Environmental Ag. Econ., Experimental Economics, Finance, International Finance/Macro, Macroeconomics Monetary, Behavioral Economics, Any field, Business Economics, Marketing, Operations Research, Statistics, Microeconomic theory, Applied microeconomics | 19 Nov 2024        | 30 Jul 2025 | N/A                                                                                                                              | N/A                                   | Economics, Macroeconomics, Microeconomics, Microeconomic theory, Finance | Doctorate         | N/A                  | https://apply.interfolio.com/39648/positions                                                                                                                                                                                     |\n",
       "| ejm      | Predoctoral Research Analyst -- Applied Microeconomics                          | Philadelphia,         | 2025-07-01   | 2 years              | Business Economics and Public Policy, Wharton School             | University of Pennsylvania            | Research Assistant (Pre-Doc) | Development Growth, Environmental Ag. Econ., Experimental Economics, Labor Demographic Economics, Public Economics, Behavioral Economics                                                                                                                                                        | 9 Oct 2024         | 1 Jul 2025  | Arthur van Benthem, Susanna Berkouwer, Benjamin Lockwood, Corinne Low, Judd Kessler, Alex Rees-Jones                             | University of Pennsylvania            | Economics                                                                | Bachelors         | 55,000 to 60,000 USD | https://wd1.myworkdaysite.com/en-US/recruiting/upenn/careers-at-penn/details/Faculty-Research-Analyst--Business--Economics--and-Public-Policy-Department--Wharton-School_JR00098140-1?jobFamily=ac2a3e0e9a860145e03c7bdc4209c207 |\n",
       "| ejm      | Research Assistant                                                              | (see ad for location) | 2025-07-01   | 6 months             | Animal Welfare Economics Working Group                           | N/A                                   | Research Assistant           | Any field                                                                                                                                                                                                                                                                                       | 15 Dec 2024        | 15 Feb 2025 | N/A                                                                                                                              | N/A                                   |                                                                          | Bachelors         | 50 USD               | https://docs.google.com/forms/d/e/1FAIpQLSfi18yuyB6O4KiefLlYMqYTvD2HSNtqwpZnW_ZPPUz1cUp4yA/viewform?usp=sf_link                                                                                                                  |\n",
       "| ejm      | Research Assistant (CAGE)                                                       | Coventry,             | 2025-07-01   | 18 months            | Economics                                                        | University of Warwick                 | Research Assistant           | Any field                                                                                                                                                                                                                                                                                       | 13 Feb 2025        | 17 Mar 2025 | N/A                                                                                                                              | University of Warwick                 |                                                                          | Masters           | N/A                  | N/A                                                                                                                                                                                                                              |\n",
       "| ejm      | PhD scholarships in Economics and Management on Ports as Energy Transition Hubs | Frederiksberg,        | 2025-09-01   | 36 months            | Department of Economics                                          | Copenhagen Business School            | Doctoral student             | Business Economics Management, General                                                                                                                                                                                                                                                          | 22 Jan 2025        | 17 Mar 2025 | and professors, supported by research related PhD courses                                                                        | Copenhagen Business School            | Economics                                                                | Masters           | N/A                  | https://candidate.hr-manager.net/ApplicationInit.aspx?cid=1309&ProjectId=147437&DepartmentId=18993&MediaId=4614&SkipAdvertisement=true                                                                                           |\n",
       "| ejm      | 1 Research Grant, IGIER Research Center                                         | Milano,               | 2025-05-01   | 36 months            | Economics                                                        | Bocconi University                    | Postdoctoral Scholar         | Labor Demographic Economics, Political Economy, Management, Information Technology                                                                                                                                                                                                              | 16 Dec 2024        | 9 Mar 2025  | N/A                                                                                                                              | Bocconi University                    | Economics                                                                | Doctorate         | N/A                  | N/A                                                                                                                                                                                                                              |\n",
       "| ejm      | Post-Doctoral Associate in the Division of Social Science [Economics]           | Abu Dhabi,            | 2025-05-01   | 2 years              | Economics                                                        | New York University Abu Dhabi         | Research Assistant           | Macroeconomics Monetary                                                                                                                                                                                                                                                                         | 16 Nov 2024        | 1 Dec 2024  | Jean Imbs, Laurent Pauwels                                                                                                       | New York University Abu Dhabi         | Economics, Macroeconomics                                                | Doctorate         | N/A                  | https://nyuad.nyu.edu/content/dam/nyuad/about/careers/magazines/NYU-Abu-Dhabi-Compensation-and-Benefits.pdf                                                                                                                      |\n",
       "| ejm      | Research Assistant                                                              | Boston,               | 2025-05-01   | 1 year               | FutureTech                                                       | Massachusetts Institute of Technology | Research Assistant           | Research Assistant (Pre-Doc) Econometrics                                                                                                                                                                                                                                                       | 15 Jan 2025        | 1 Mar 2025  | of economics, international studies at Boston College, holding the White Family assistant professorship chair between 2020, 2023 | Massachusetts Institute of Technology |                                                                          | Bachelors         | N/A                  | N/A                                                                                                                                                                                                                              |\n",
       "| ejm      | Research Engineer or Postdoctoral position in Health Economics                  | Cergy-Pontoise cedex, | 2025-05-01   | 1 year               | Information Systems, Decision Sciences and Statistics Department | ESSEC Business School                 | Postdoctoral Scholar         | Other academic Research Assistant Econometrics Health Education Welfare                                                                                                                                                                                                                         | 13 Aug 2024        | 15 Sep 2024 | N/A                                                                                                                              | ESSEC Business School                 |                                                                          | Masters           | N/A                  | mailto:lamiraud@essec.edu                                                                                                                                                                                                        |\n",
       "| ejm      | Several postdoctoral researchers in microeconomic theory                        | Bonn,                 | 2025-08-01   | 3 years              | Department of Economics                                          | University of Bonn                    | Postdoctoral Scholar         | Research Assistant Microeconomic theory                                                                                                                                                                                                                                                         | 5 Nov 2024         | 28 Feb 2025 | N/A                                                                                                                              | University of Bonn                    | Microeconomic theory                                                     | Doctorate         | N/A                  | https://econjobmarket.org/login                                                                                                                                                                                                  |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scrape_ejm():\n",
    "    \"\"\"\n",
    "    Scrapes the Econ Job Market (EJM) page and extracts detailed job information\n",
    "    from the newer HTML structure. Post-processing steps include:\n",
    "      - Merging single/multiple salaries into one cell.\n",
    "      - Parsing sponsor(s) from text referencing \"Professors ...\"\n",
    "      - Removing extraneous punctuation in 'fields' (bullet '‚Ä¢', semicolon ';', repeated commas).\n",
    "      - Replacing 'link' with the final application link (or \"N/A\" if missing).\n",
    "      - Inheriting 'start_date' if 'Flexible' from a previous non-Flexible record.\n",
    "    \n",
    "    Returns a list of dictionaries.\n",
    "    \"\"\"\n",
    "    EJM_URL = \"https://econjobmarket.org/market\"\n",
    "    jobs = []\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(EJM_URL)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Each job listing is typically under <div class=\"panel panel-info\">\n",
    "        panels = soup.find_all(\"div\", class_=\"panel panel-info\")\n",
    "        for panel in panels:\n",
    "            job = {}\n",
    "            job[\"source\"] = \"ejm\"\n",
    "            \n",
    "            # ---------- MAIN ROW (col-md-4, col-md-4, col-md-2, col-md-2) ----------\n",
    "            main_row = panel.find(\"div\", class_=\"row\")\n",
    "            if not main_row:\n",
    "                continue\n",
    "            \n",
    "            cols = main_row.find_all(\"div\", recursive=False)\n",
    "            \n",
    "            # --- FIRST COLUMN: title, location, start_date, duration ---\n",
    "            if len(cols) >= 1:\n",
    "                first_col = cols[0]\n",
    "                title_a = first_col.find(\"a\", id=lambda x: x and x.startswith(\"title-\"))\n",
    "                \n",
    "                if title_a:\n",
    "                    job[\"program_title\"] = title_a.get_text(strip=True)\n",
    "                    # We'll store a temporary link here; final link will become 'application_link'\n",
    "                    job[\"temp_link\"] = title_a.get(\"href\", \"\").strip()\n",
    "                else:\n",
    "                    job[\"program_title\"] = \"N/A\"\n",
    "                    job[\"temp_link\"] = \"\"\n",
    "                \n",
    "                col_text = first_col.get_text(separator=\"\\n\", strip=True).split(\"\\n\")\n",
    "                # Often line 2 is location\n",
    "                job[\"location\"] = col_text[1].strip() if len(col_text) >= 2 else \"N/A\"\n",
    "                \n",
    "                job[\"start_date\"] = \"N/A\"\n",
    "                job[\"duration\"] = \"N/A\"\n",
    "                for line in col_text:\n",
    "                    lower_line = line.lower()\n",
    "                    if lower_line.startswith(\"starts\"):\n",
    "                        clean_line = line.replace(\"Starts\", \"\").replace(\".\", \"\").strip()\n",
    "                        job[\"start_date\"] = clean_line if clean_line else \"N/A\"\n",
    "                    elif lower_line.startswith(\"duration\"):\n",
    "                        clean_line = line.replace(\"Duration:\", \"\").strip()\n",
    "                        job[\"duration\"] = clean_line if clean_line else \"N/A\"\n",
    "            \n",
    "            # --- SECOND COLUMN: department, university ---\n",
    "            if len(cols) >= 2:\n",
    "                second_col = cols[1]\n",
    "                lines_2 = second_col.get_text(separator=\"\\n\", strip=True).split(\"\\n\")\n",
    "                job[\"department\"] = lines_2[0].strip() if len(lines_2) >= 1 else \"N/A\"\n",
    "                job[\"university\"] = lines_2[1].strip() if len(lines_2) >= 2 else \"N/A\"\n",
    "            \n",
    "            # --- THIRD COLUMN: program_type, fields ---\n",
    "            if len(cols) >= 3:\n",
    "                third_col = cols[2]\n",
    "                program_text = third_col.get_text(separator=\"\\n\", strip=True).split(\"\\n\", 1)\n",
    "                job[\"program_type\"] = program_text[0].strip() if program_text else \"N/A\"\n",
    "                \n",
    "                fields_div = third_col.find(\"div\", id=re.compile(r\"cats-\\d+\"))\n",
    "                if fields_div:\n",
    "                    fields_raw = fields_div.get_text(separator=\", \", strip=True)\n",
    "                else:\n",
    "                    fields_raw = program_text[1].strip() if len(program_text) > 1 else \"\"\n",
    "                \n",
    "                # Clean fields: remove bullet dots, semicolons, repeated commas\n",
    "                fields_clean = re.sub(r\"[‚Ä¢;]\", \"\", fields_raw)\n",
    "                fields_clean = re.sub(r\",\\s*,\", \",\", fields_clean)\n",
    "                fields_clean = re.sub(r\"\\s+\", \" \", fields_clean).strip(\" ,\")\n",
    "                job[\"fields\"] = fields_clean if fields_clean else \"N/A\"\n",
    "            \n",
    "            # --- FOURTH COLUMN: publication_date, deadline ---\n",
    "            if len(cols) >= 4:\n",
    "                fourth_col = cols[3]\n",
    "                spans = fourth_col.find_all(\"span\")\n",
    "                \n",
    "                job[\"publication_date\"] = spans[0].get_text(strip=True) if len(spans) > 0 else \"N/A\"\n",
    "                job[\"deadline\"] = spans[1].get_text(strip=True) if len(spans) > 1 else \"N/A\"\n",
    "            else:\n",
    "                job[\"program_type\"] = job.get(\"program_type\") or \"N/A\"\n",
    "                job[\"publication_date\"] = \"N/A\"\n",
    "                job[\"deadline\"] = \"N/A\"\n",
    "                job[\"fields\"] = job.get(\"fields\") or \"N/A\"\n",
    "            \n",
    "            # Placeholders for collapsed info\n",
    "            job[\"sponsor\"] = \"N/A\"\n",
    "            job[\"institution\"] = job[\"university\"]\n",
    "            job[\"main_field\"] = extract_main_field(job[\"fields\"])\n",
    "            job[\"degree_required\"] = \"N/A\"\n",
    "            job[\"salary_range\"] = \"N/A\"\n",
    "            job[\"application_link\"] = \"N/A\"\n",
    "            \n",
    "            # ---------- COLLAPSE BLOCK (extended info) ----------\n",
    "            if title_a:\n",
    "                collapse_id = title_a.get(\"href\", \"\")\n",
    "                if collapse_id.startswith(\"#\"):\n",
    "                    collapse_div_id = collapse_id[1:]\n",
    "                    collapse_div = panel.find(\"div\", id=collapse_div_id)\n",
    "                    if collapse_div:\n",
    "                        # We'll parse the entire collapse text in one go\n",
    "                        collapse_text = collapse_div.get_text(separator=\"\\n\", strip=True)\n",
    "                        \n",
    "                        # Parse sponsor(s) from text with \"Professors\" ...\n",
    "                        # We'll look for a pattern: \"Professors (.*?).\" or \"Professor (.*?).\"\n",
    "                        # This is a heuristic; adjust to your content.\n",
    "                        prof_match = re.search(\n",
    "                            r'(?:[Pp]rofessors?\\s+)(.*?)(?:\\.|$)', collapse_text\n",
    "                        )\n",
    "                        if prof_match:\n",
    "                            sponsor_str = prof_match.group(1)\n",
    "                            # Replace ' and ' with comma\n",
    "                            sponsor_str = sponsor_str.replace(\" and \", \", \")\n",
    "                            # Split by commas\n",
    "                            sponsor_list = [x.strip() for x in sponsor_str.split(\",\") if x.strip()]\n",
    "                            # Re-join with commas\n",
    "                            job[\"sponsor\"] = \", \".join(sponsor_list)\n",
    "                        \n",
    "                        # We'll search within <div> tags with <strong> for structured data\n",
    "                        additional_divs = collapse_div.find_all(\"div\")\n",
    "                        for div_item in additional_divs:\n",
    "                            strong_tag = div_item.find(\"strong\")\n",
    "                            if strong_tag:\n",
    "                                label = strong_tag.get_text(strip=True).lower()\n",
    "                                val = div_item.get_text(separator=\"\\n\", strip=True)\n",
    "                                # remove the strong text from val\n",
    "                                val = val.replace(strong_tag.get_text(strip=True), \"\").strip(\": \\n\")\n",
    "                                \n",
    "                                if \"degree required\" in label:\n",
    "                                    job[\"degree_required\"] = val if val else \"N/A\"\n",
    "                                elif \"job start date\" in label:\n",
    "                                    job[\"start_date\"] = val if val else \"N/A\"\n",
    "                                elif \"job duration\" in label:\n",
    "                                    job[\"duration\"] = val if val else \"N/A\"\n",
    "                                elif \"salary\" in label:\n",
    "                                    # unify multiple lines for salary\n",
    "                                    raw_lines = val.split(\"\\n\")\n",
    "                                    unified = \" \".join(x.strip() for x in raw_lines if x.strip())\n",
    "                                    job[\"salary_range\"] = unified if unified else \"N/A\"\n",
    "                        \n",
    "                        # Try to parse \"To Apply\" link\n",
    "                        apply_paragraph = collapse_div.find(\"p\", text=re.compile(r\"To\\s+Apply\", re.IGNORECASE))\n",
    "                        if apply_paragraph:\n",
    "                            next_link = apply_paragraph.find_next(\"a\", href=True)\n",
    "                            if next_link:\n",
    "                                job[\"application_link\"] = next_link.get(\"href\", \"N/A\")\n",
    "                        else:\n",
    "                            # or search any <a> with 'apply' in text\n",
    "                            apply_a = collapse_div.find(\"a\", href=True, text=re.compile(r\"apply\", re.IGNORECASE))\n",
    "                            if apply_a:\n",
    "                                job[\"application_link\"] = apply_a.get(\"href\", \"N/A\")\n",
    "            \n",
    "            jobs.append(job)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error during EJM scraping:\", e)\n",
    "    \n",
    "    # ---------- POST-PROCESSING ----------\n",
    "    # (1) Replace 'link' with final 'application_link', or \"N/A\" if missing/'https://econjobmarket.org'\n",
    "    # (2) If 'start_date' == 'Flexible', copy from the nearest preceding non-Flexible record\n",
    "    for i, job in enumerate(jobs):\n",
    "        # (1) link substitution\n",
    "        app_link = job[\"application_link\"]\n",
    "        if not app_link or app_link.strip() == \"\" or app_link.strip() == \"https://econjobmarket.org\":\n",
    "            job[\"link\"] = \"N/A\"\n",
    "        else:\n",
    "            job[\"link\"] = app_link\n",
    "        \n",
    "        # (2) if 'start_date' is 'Flexible', inherit from previous\n",
    "        sd = job.get(\"start_date\")\n",
    "        if isinstance(sd, str) and sd.lower() == \"flexible\":\n",
    "            new_date = \"N/A\"\n",
    "            # look upward\n",
    "            for j in range(i-1, -1, -1):\n",
    "                prev_sd = jobs[j].get(\"start_date\")\n",
    "                if prev_sd and isinstance(prev_sd, str) and prev_sd.lower() != \"flexible\":\n",
    "                    new_date = prev_sd\n",
    "                    break\n",
    "            job[\"start_date\"] = new_date  # can be \"N/A\" if never found\n",
    "    \n",
    "    # Remove temp columns\n",
    "    for job in jobs:\n",
    "        if \"temp_link\" in job:\n",
    "            del job[\"temp_link\"]\n",
    "        if \"application_link\" in job:\n",
    "            del job[\"application_link\"]\n",
    "    \n",
    "    return jobs\n",
    "\n",
    "\n",
    "df  = pd.DataFrame(scrape_ejm()).head(10).to_markdown(index=False)\n",
    "\n",
    "display(Markdown(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV & Email Handling Section üìä‚úâÔ∏è\n",
    "\n",
    "This section contains helper functions to manage your job database and send email notifications when new opportunities are detected.\n",
    "\n",
    "### 1. Reading Existing Jobs from a CSV File üìÇ\n",
    "\n",
    "The `read_existing_jobs()` function reads a CSV file that contains saved job listings and returns a **set** of job links that are already recorded.  \n",
    "- It checks if the file exists.  \n",
    "- It uses Python's `csv.DictReader` to iterate over rows and collects the \"link\" field for each job.  \n",
    "\n",
    "### 2. Appending New Jobs to the CSV File üíæ\n",
    "\n",
    "The `append_jobs_to_csv()` function takes a list of job dictionaries and appends them to the specified CSV file.\n",
    "- If the CSV file doesn't exist, it creates the file and writes the header.  \n",
    "- It then appends each job as a new row.  \n",
    "\n",
    "### 3. Sending Email Notifications ‚úâÔ∏è\n",
    "\n",
    "- **Purpose:**  \n",
    "  This function sends an email notification whenever new job records are found.  \n",
    "  - **Single Record:** The subject is set to the university name from that record.\n",
    "  - **Multiple Records:** The subject lists the unique university names (e.g., \"University A, University B\").\n",
    "\n",
    "- **Email Body:**  \n",
    "  The email body is constructed as an HTML document with a styled table that lists:\n",
    "  - **Source** (e.g., \"predoc\", \"nber\", \"ejm\")\n",
    "  - **Program Title**\n",
    "  - **Clickable Link** (each link is rendered as a clickable hyperlink)\n",
    "  - **Sponsor**\n",
    "  - **Institution**\n",
    "  - **Fields**\n",
    "  - **Main Field**\n",
    "  - **Deadline**\n",
    "  - **University**\n",
    "  - **Program Type**\n",
    "  - **Publication Date**\n",
    "\n",
    "- **How It Works:**  \n",
    "  1. **Subject Creation:**  \n",
    "     The function extracts university names from each job record. If there's only one record, it uses that university name; if multiple, it joins all unique names.\n",
    "  \n",
    "  2. **HTML Table Construction:**  \n",
    "     An HTML table is built with one row per job record, ensuring that links are rendered as clickable hyperlinks.\n",
    "  \n",
    "  3. **Email Assembly:**  \n",
    "     The email is composed as a multipart message with both plain text and HTML parts.\n",
    "  \n",
    "  4. **Sending the Email:**  \n",
    "     Using Python's `smtplib`, the function logs in to the SMTP server (defaulting to Gmail) and sends the email.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_none_or_empty_in_list_of_dicts(jobs):\n",
    "    \"\"\"\n",
    "    Ensures all job dictionaries have consistent formatting:\n",
    "    - Replace None or empty values with \"N/A\"\n",
    "    - Strip extra whitespace\n",
    "    - Convert to lowercase for consistency\n",
    "    \"\"\"\n",
    "    cleaned_jobs = []\n",
    "    for job in jobs:\n",
    "        cleaned_job = {\n",
    "            str(k).strip().lower(): str(v).strip() if v and v.strip() else \"N/A\"\n",
    "            for k, v in job.items()\n",
    "        }\n",
    "        cleaned_jobs.append(cleaned_job)\n",
    "    return cleaned_jobs\n",
    "\n",
    "\n",
    "\n",
    "def read_existing_jobs(xml_file):\n",
    "    \"\"\"\n",
    "    Reads existing job entries from XML and returns a dictionary of frozenset job signatures,\n",
    "    categorized by 'source' (e.g., Predoc, NBER, EJM).\n",
    "    \n",
    "    If the XML file does not exist, returns an empty dictionary.\n",
    "    \"\"\"\n",
    "    existing_signatures = {}\n",
    "\n",
    "    if os.path.exists(xml_file):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for entry in root.findall(\"entry\"):\n",
    "            job_data = {child.tag.strip(): child.text.strip() if child.text else \"N/A\" for child in entry}\n",
    "            job_signature = frozenset(sorted(job_data.items()))  # Sort keys to ensure consistency\n",
    "            \n",
    "            source = job_data.get(\"source\", \"Unknown\")  # Extract source\n",
    "            \n",
    "            if source not in existing_signatures:\n",
    "                existing_signatures[source] = set()  # Create a set for this source if it doesn‚Äôt exist\n",
    "            \n",
    "            existing_signatures[source].add(job_signature)  # Store the signature under the correct source\n",
    "\n",
    "    print(\"\\nüîç Debug: Existing Job Signatures by Source from XML\")\n",
    "    for src, sigs in existing_signatures.items():\n",
    "        print(f\"üìÅ {src}: {len(sigs)} jobs stored\")\n",
    "    \n",
    "    return existing_signatures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def append_jobs_to_xml(xml_file, jobs):\n",
    "    \"\"\"\n",
    "    Saves a list of job dictionaries into an XML file.\n",
    "    \n",
    "    - If the file does not exist, it creates a new XML structure.\n",
    "    - If the file exists, it appends only new job entries while avoiding duplicates.\n",
    "    \"\"\"\n",
    "    # Load existing XML or create a new root if the file doesn't exist\n",
    "    if os.path.exists(xml_file):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "    else:\n",
    "        root = ET.Element(\"jobs\")  # Create root element\n",
    "\n",
    "    # Read existing jobs to avoid duplicates\n",
    "    existing_signatures = read_existing_jobs(xml_file)\n",
    "\n",
    "    new_entries_count = 0  # Track new records added\n",
    "\n",
    "    for job in jobs:\n",
    "        # Convert job dict into a frozenset signature\n",
    "        job_str_dict = {str(k).strip(): str(v).strip() for k, v in job.items() if v != \"N/A\"}\n",
    "        job_signature = frozenset(sorted(job_str_dict.items()))\n",
    "\n",
    "        if job_signature not in existing_signatures:\n",
    "            # This is a new job! Add it to XML.\n",
    "            entry = ET.SubElement(root, \"entry\")\n",
    "            \n",
    "            for key, value in job.items():\n",
    "                field = ET.SubElement(entry, key)\n",
    "                field.text = value if value.strip() else \"N/A\"  # Ensure no empty values\n",
    "            \n",
    "            new_entries_count += 1\n",
    "\n",
    "    # Only save if new entries were added\n",
    "    if new_entries_count > 0:\n",
    "        tree = ET.ElementTree(root)\n",
    "        tree.write(xml_file, encoding=\"utf-8\", xml_declaration=True)\n",
    "        print(f\"‚úÖ {new_entries_count} new job(s) added to {xml_file}\")\n",
    "    else:\n",
    "        print(\"üîπ No new jobs found; XML file remains unchanged.\")\n",
    "\n",
    "\n",
    "\n",
    "def send_email_new_jobs(new_jobs, sender_email, sender_password, receiver_email, smtp_server=\"smtp.gmail.com\", smtp_port=587):\n",
    "    \"\"\"\n",
    "    Sends an email with new job records using an HTML template.\n",
    "    \n",
    "    - Uses Jinja2 for templating.\n",
    "    - Loads the email HTML template from `templates/email.html`.\n",
    "    - Displays \"Apply\" buttons instead of raw links.\n",
    "    - Shows the latest update timestamp.\n",
    "    - Provides links to contribute or report issues on GitHub.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count new jobs for the email subject\n",
    "    num_jobs = len(new_jobs)\n",
    "    subject = f\"New Job Opportunities Found ({num_jobs})\"\n",
    "\n",
    "    # Get the current date & time\n",
    "    update_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Load the email template using Jinja2\n",
    "    env = Environment(loader=FileSystemLoader(\"templates\"))\n",
    "    template = env.get_template(\"email.html\")\n",
    "    \n",
    "    # Render the template with dynamic values\n",
    "    html_body = template.render(\n",
    "        new_jobs=new_jobs,\n",
    "        update_time=update_time,\n",
    "        github_repo_url=GITHUB_REPO_URL,\n",
    "        github_issue_url=GITHUB_ISSUE_URL\n",
    "    )\n",
    "\n",
    "    # Create a multipart email message (plain text and HTML)\n",
    "    msg = MIMEMultipart(\"alternative\")\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "\n",
    "    # Plain text fallback\n",
    "    text_body = f\"{num_jobs} new research positions found. Please view this email in an HTML-compatible client.\"\n",
    "\n",
    "    part1 = MIMEText(text_body, \"plain\")\n",
    "    part2 = MIMEText(html_body, \"html\")\n",
    "\n",
    "    msg.attach(part1)\n",
    "    msg.attach(part2)\n",
    "\n",
    "    # Send the email via SMTP\n",
    "    try:\n",
    "        with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "            server.starttls()  # Secure the connection\n",
    "            server.login(sender_email, sender_password)\n",
    "            server.send_message(msg)\n",
    "        print(\"Email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send email:\", e)\n",
    "\n",
    "\n",
    "def find_new_jobs():\n",
    "    \"\"\"\n",
    "    Scrapes jobs from each source, checks for duplicates using XML storage,\n",
    "    and returns a list of newly detected jobs.\n",
    "    \"\"\"\n",
    "    # Scrape jobs from each source.\n",
    "    predoc_jobs = scrape_predoc()\n",
    "    nber_jobs = scrape_nber()\n",
    "    ejm_jobs = scrape_ejm()\n",
    "\n",
    "    # Combine all job records into a single list.\n",
    "    all_jobs = predoc_jobs + nber_jobs + ejm_jobs\n",
    "    all_jobs = replace_none_or_empty_in_list_of_dicts(all_jobs)\n",
    "\n",
    "    if not all_jobs:\n",
    "        print(\"No jobs were scraped.\")\n",
    "        return []\n",
    "\n",
    "    # Read existing job signatures from XML.\n",
    "    existing_signatures = read_existing_jobs(XML_FILE)\n",
    "\n",
    "    print(\"\\nüîç Debug: Checking New Jobs Against Filtered Existing Records\")\n",
    "    \n",
    "    new_jobs = []\n",
    "    for job in all_jobs:\n",
    "        job_str_dict = {\n",
    "            str(k).strip().lower(): str(v).strip() if v and v.strip() else \"N/A\"\n",
    "            for k, v in job.items()\n",
    "        }\n",
    "        job_signature = frozenset(sorted(job_str_dict.items()))\n",
    "\n",
    "        # Use `source` to filter existing records before comparison\n",
    "        job_source = job.get(\"source\", \"Unknown\")\n",
    "\n",
    "        if job_source in existing_signatures and job_signature in existing_signatures[job_source]:\n",
    "            print(f\"‚úÖ Job Already Exists in XML ({job_source})\")\n",
    "        else:\n",
    "            print(f\"‚ùå New Job Detected! Adding to list. ({job_source})\")\n",
    "            new_jobs.append(job)\n",
    "\n",
    "    print(f\"\\nFound {len(new_jobs)} new job(s).\")\n",
    "    return new_jobs  # Return list of new jobs\n",
    "\n",
    "\n",
    "def debug_email_with_existing_jobs(existing_jobs):\n",
    "    \"\"\"\n",
    "    Debug function to render the email using existing jobs.\n",
    "    \"\"\"\n",
    "    from jinja2 import Environment, FileSystemLoader\n",
    "    import datetime\n",
    "\n",
    "    # Flatten jobs from all sources into a single list\n",
    "    all_jobs = []\n",
    "    for source, jobs in existing_jobs.items():\n",
    "        for job in jobs:\n",
    "            # Convert frozenset back to dict if necessary\n",
    "            if isinstance(job, frozenset):\n",
    "                job = dict(job)\n",
    "            all_jobs.append(job)\n",
    "\n",
    "    if not all_jobs:\n",
    "        print(\"‚ö†Ô∏è No existing jobs found in the XML file.\")\n",
    "        return\n",
    "\n",
    "    # Take only the first 5 jobs for debugging\n",
    "    sample_jobs = all_jobs[:5]\n",
    "\n",
    "    print(\"\\nüîç DEBUG: First 5 Jobs for Email Rendering\")\n",
    "    for job in sample_jobs:\n",
    "        print(job)\n",
    "\n",
    "    # Load the email template using Jinja2\n",
    "    env = Environment(loader=FileSystemLoader(\"templates\"))\n",
    "    template = env.get_template(\"email.html\")\n",
    "\n",
    "    # Get the current timestamp\n",
    "    update_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Render the email with the sample job data\n",
    "    email_content = template.render(\n",
    "        new_jobs=sample_jobs,\n",
    "        update_time=update_time,\n",
    "        github_repo_url=\"https://github.com/your_repo\",\n",
    "        github_issue_url=\"https://github.com/your_repo/issues\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nüìù DEBUG: Rendered Email Content (Raw HTML):\\n\", email_content)\n",
    "\n",
    "    # Save the output to a file for testing\n",
    "    with open(\"debug_email_output.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(email_content)\n",
    "\n",
    "    print(\"\\n‚úÖ Email template successfully rendered and saved as 'debug_email_output.html'.\")\n",
    "\n",
    "\n",
    "\n",
    "# Load existing jobs from XML (assuming you have a function for this)\n",
    "#existing_jobs = read_existing_jobs(XML_FILE)\n",
    "\n",
    "# Call the debug function\n",
    "#debug_email_with_existing_jobs(existing_jobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function: Scrape, Update, and Notify üöÄüìä‚úâÔ∏è\n",
    "\n",
    "This **main()** function orchestrates the complete workflow of the project. It:\n",
    "\n",
    "- **Scrapes Job Data:**  \n",
    "  Calls the scraping functions for all three sources (Predoc, NBER, EJM) to collect job postings.\n",
    "\n",
    "- **Filters New Jobs:**  \n",
    "  Reads an existing CSV file (acting as a simple database) to get a set of already recorded job links. Then, it filters out jobs that are already present.\n",
    "\n",
    "- **Sends Notifications:**  \n",
    "  For each new job found, the function sends an email notification with the job details.\n",
    "\n",
    "- **Updates the CSV Database:**  \n",
    "  Finally, it appends the new job entries to the CSV file for future reference.\n",
    "\n",
    "> **Note:**  \n",
    "> Ensure that your SMTP credentials (i.e. `SENDER_EMAIL` and `SENDER_PASSWORD`) are set up and that the scraping functions (`scrape_predoc()`, `scrape_nber()`, and `scrape_ejm()`) along with CSV and email helper functions are defined before running `main()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function. Calls find_new_jobs, saves new jobs to XML,\n",
    "    and optionally sends email notifications.\n",
    "    \"\"\"\n",
    "    new_jobs = find_new_jobs()  # Call the new function\n",
    "\n",
    "    if new_jobs:\n",
    "        # Save new jobs to XML instead of CSV. üíæ\n",
    "        append_jobs_to_xml(XML_FILE, new_jobs)\n",
    "        \n",
    "        # Retrieve SMTP credentials from environment variables. üîí\n",
    "        sender_email    = os.getenv('SENDER_EMAIL')\n",
    "        sender_password = os.getenv('SENDER_PASSWORD')\n",
    "        receiver_email  = os.getenv('SENDER_EMAIL')\n",
    "        \n",
    "        # Convert new jobs to a DataFrame for better visualization.\n",
    "        df_new = pd.DataFrame(new_jobs).head(10)\n",
    "        md_table = df_new.to_markdown(index=False)\n",
    "        \n",
    "        # Uncomment to send email notifications\n",
    "        send_email_new_jobs(new_jobs, sender_email, sender_password, receiver_email)\n",
    "        \n",
    "    else:\n",
    "        print(\"No new jobs found.\")\n",
    "        if os.path.exists(XML_FILE):\n",
    "            df_new = pd.read_xml(XML_FILE).head(10)\n",
    "            md_table = df_new.to_markdown(index=False)\n",
    "        else:\n",
    "            md_table = \"No XML file found.\"\n",
    "\n",
    "    # Display the table in the notebook (either new jobs or existing XML).\n",
    "    display(Markdown(md_table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zd/nzwwg11s06sf2dv5349vbjxh0000gn/T/ipykernel_1106/4290271320.py:156: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  apply_paragraph = collapse_div.find(\"p\", text=re.compile(r\"To\\s+Apply\", re.IGNORECASE))\n",
      "/var/folders/zd/nzwwg11s06sf2dv5349vbjxh0000gn/T/ipykernel_1106/4290271320.py:163: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  apply_a = collapse_div.find(\"a\", href=True, text=re.compile(r\"apply\", re.IGNORECASE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Debug: Existing Job Signatures by Source from XML\n",
      "\n",
      "üîç Debug: Checking New Jobs Against Filtered Existing Records\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (Predoc)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (NBER)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "‚ùå New Job Detected! Adding to list. (ejm)\n",
      "\n",
      "Found 308 new job(s).\n",
      "\n",
      "üîç Debug: Existing Job Signatures by Source from XML\n",
      "‚úÖ 308 new job(s) added to jobs.xml\n",
      "Email sent successfully!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| source   | program_title                                | link                   | sponsor                                                    | institution                                                                             | fields                                                                            | deadline                                                                                                                                                                                                            | university   | program_type   | publication_date   | main_field                  |   location |   start_date |   duration |   department |   degree_required |   salary_range |\n",
       "|:---------|:---------------------------------------------|:-----------------------|:-----------------------------------------------------------|:----------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------|:---------------|:-------------------|:----------------------------|-----------:|-------------:|-----------:|-------------:|------------------:|---------------:|\n",
       "| Predoc   | Research Associates                          | https://bit.ly/3Xhfcvq | N/A                                                        | N/A                                                                                     | Education, Finance, Labor, Macro, Public Policy, and Urban                        | Rolling In addition to a multi-institutional job pool, this website also provides general information about opportunities within the Federal Reserve System as well as up-to-date information re specific openings. | N/A          | N/A            | N/A                | Finance, Public Policy      |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Pre-Doctoral Positions                       | https://bit.ly/3CM4IxV | Abhishek Nagaraj (UC Berkeley) and Matteo Tranchero (Penn) | UC Berkeley‚Äôs Haas School of Business; Wharton School of the University of Pennsylvania | Applied economics, innovation, entrepreneurship, data science and tech innovation | Rolling                                                                                                                                                                                                             | N/A          | N/A            | N/A                | Economics, Entrepreneurship |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Pre-Doctoral Technical Associate             | https://bit.ly/4hBFgtU | N/A                                                        | N/A                                                                                     | N/A                                                                               | N/A                                                                                                                                                                                                                 | N/A          | N/A            | N/A                | N/A                         |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Pre-Doctoral Technical Associate             | https://bit.ly/4er9iOY | N/A                                                        | N/A                                                                                     | N/A                                                                               | N/A                                                                                                                                                                                                                 | N/A          | N/A            | N/A                | N/A                         |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Pre-Doctoral Research Associate in Economics | https://bit.ly/4jQlfBs | Matthew Pecenco                                            | Brown University                                                                        | Labor, Crime, Housing                                                             | Applications will be accepted and reviewed on a rolling basis.                                                                                                                                                      | N/A          | N/A            | N/A                | Economics                   |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Full-Time Research Assistant                 | https://bit.ly/4hwY3a0 | Matthew Baron                                              | National Bureau of Economic Research                                                    | Banking, Financial Crises, Financial History                                      | Rolling                                                                                                                                                                                                             | N/A          | N/A            | N/A                | N/A                         |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Pre-Doctoral Fellowship                      | https://bit.ly/3WXU7GY | Hans-Joachim Voth                                          | University of Zurich                                                                    | Economic History, Political Economy, Cultural Economics                           | Applications will be reviewed immediately and are welcome until all positions are filled.                                                                                                                           | N/A          | N/A            | N/A                | Economics                   |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Research Professional in Accounting          | https://bit.ly/4hyJouK | Professor Philip Berger                                    | The University of Chicago Booth School of Business                                      | Accounting, corporate finance, and labor economics.                               | Applications are reviewed on a rolling basis; the initial full review will be March 15, 2025.                                                                                                                       | N/A          | N/A            | N/A                | Economics, Finance          |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Research Professional in Marketing           | https://bit.ly/3Eupeng | Professor Andreas Kraft                                    | University of Chicago Booth School of Business                                          | N/A                                                                               | N/A                                                                                                                                                                                                                 | N/A          | N/A            | N/A                | N/A                         |        nan |          nan |        nan |          nan |               nan |            nan |\n",
       "| Predoc   | Research Professional in Behavioral Science  | https://bit.ly/3QkttnL | Professor Alexander Todorov                                | University of Chicago Booth School of Business                                          | Behavioral Science                                                                | Applications are reviewed on a rolling basis; the initial full review will be March 1, 2025.                                                                                                                        | N/A          | N/A            | N/A                | N/A                         |        nan |          nan |        nan |          nan |               nan |            nan |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
